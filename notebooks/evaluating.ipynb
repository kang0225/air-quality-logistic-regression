{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><strong> 성능 및 평가지표 분석 </strong></h1>\n",
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "<h2> 1. Introduction </h2>\n",
    " <p style=\"font-size:16px\">📖 개요 : 본 노트북은 앞서 개발한 초미세먼지(PM2.5) 및 미세먼지(PM10) 예측 모델의 성능을 정량적으로 평가하고 분석하는 과정을 기록한 리포트이다.\n",
    " <p style=\"font-size:16px\">🏁 목표 : 훈련 데이터와 테스트 데이터 각각에 대한 모델의 예측 결과를 오차행렬(Confusion Matrix)과 분류 리포트(Classification Report)를 통해 심층적으로 분석하고, 실제 대기질 예측에 얼마나 효과적인지 정밀도(Precision), 재현율(Recall), F1-score 등의 수치를 통해 검증하고자 한다.</p>\n",
    "\n",
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "<h2> 2. Library Import </h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# 노트북 메모리 로드\n",
    "%run preprocessing.ipynb\n",
    "%run training.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>\n",
    "<h2> 3. 성능 평가 함수 선언 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_input, train_target, test_input, test_target):\n",
    "    print(\"*** 훈련 세트 성능 평가 ***\")\n",
    "    train_pred = model.predict(train_input)\n",
    "    \n",
    "    train_conf_matrix = confusion_matrix(train_target, train_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(\"[[TN, FP], [FN, TP]\")\n",
    "    print(train_conf_matrix.tolist(), \"\\n\")\n",
    "    \n",
    "    train_report = classification_report(train_target, train_pred, target_names=['양호(0)', '나쁨(1)'], zero_division=0)\n",
    "    print(\"Classification Report:\")\n",
    "    print(train_report)\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    print(\"\\n*** 테스트 세트 성능 평가 ***\")\n",
    "    test_pred = model.predict(test_input)\n",
    "    \n",
    "    test_conf_matrix = confusion_matrix(test_target, test_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(\"[[TN, FP], [FN, TP]\")\n",
    "    print(test_conf_matrix.tolist(), \"\\n\")\n",
    "\n",
    "    test_report = classification_report(test_target, test_pred, target_names=['양호(0)', '나쁨(1)'], zero_division=0)\n",
    "    print(\"Classification Report:\")\n",
    "    print(test_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px\">\n",
    "   위 함수는 학습된 분류 모델의 성능을 종합적으로 평가한다. 훈련 세트와 테스트 세트 각각의 예측 결과를 오차행렬(Confusion Matrix)과 분류 리포트(Classification Report)로 출력한다.\n",
    "</p><br>\n",
    "\n",
    "```\n",
    "train_conf_matrix = confusion_matrix(train_target, train_pred)\n",
    "test_conf_matrix = confusion_matrix(test_target, test_pred)\n",
    "print(train_conf_matrix.tolist(), \"\\n\")\n",
    "print(test_conf_matrix.tolist(), \"\\n\")\n",
    "```\n",
    "\n",
    "<p style=\"font-size:16px\">   \n",
    "   <code>confusion_matrix()</code>는 훈련 세트 및 테스트 세트에 대한 예측을 수행하고, 실제 값과 비교하여 2x2 행렬을 출력한다. [[TN, FP], [FN, TP]]와 같이 출력이 되는데 각 원소의 의미는 다음과 같다.\n",
    "   <ul>\n",
    "   <li><b>TN (True Negative)</b> : '양호(0)'를 '양호(0)'로 예측</li>\n",
    "   <li><b>FP (False Positive)</b> : '양호(0)'를 '나쁨(1)'으로 예측</li>\n",
    "   <li><b>FN (False Negative)</b> : '나쁨(1)'을 '양호(0)'로 예측</li>\n",
    "   <li><b>TP (True Positive)</b> : '나쁨(1)'을 '나쁨(1)'으로 예측</li>\n",
    "   </ul>\n",
    "</p><br>\n",
    "\n",
    "```\n",
    "train_report = classification_report(train_target, train_pred, target_names=['양호(0)', '나쁨(1)'], zero_division=0)\n",
    "test_report = classification_report(test_target, test_pred, target_names=['양호(0)', '나쁨(1)'], zero_division=0)\n",
    "print(train_report)\n",
    "print(test_report)\n",
    "```\n",
    "\n",
    "<p style=\"font-size:16px\">\n",
    "   <code>classification_report()</code>는 훈련 세트 및 테스트 세트에 대한 분류 리포트를 통해 정밀도(Prevision), 재현율(Recall), F1 점수(F1-score), 서포트(Support)를 출력한다. 각 점수의 의미는 다음과 같다.\n",
    "   <ul>\n",
    "   <li><b>정밀도 (Precision)</b> : '나쁨(1)'으로 예측한 날 중, '나쁨(1)'인 날인 비율 (정밀도가 높아야 FP가 감소)</li>\n",
    "   <li><b>재현율 (Recall)</b> : '나쁨(1)'인 날을 '나쁨(1)'으로 맞춘 비율 (재현율이 높아야 FN이 감소)</li>\n",
    "   <li><b>F1-점수 (F1-score)</b> : 정밀도와 재현율이 균형을 얼마나 이루는지에 대한 점수</li>\n",
    "   <li><b>서포트 (Support)</b> : '양호(0)'와 '나쁨(1)' 각각의 클래스 수</li>\n",
    "   </ul>\n",
    "\n",
    "   FP(False Positive)와 FN(False Negative)는 한쪽이 올라가면 다른 한쪽이 내려가는 음의 상관관계이다. 따라서 두 수치를 균형있게 예측하기 위해서는 F1 점수를 성능 지표의 기준으로 지정해야 한다.\n",
    "</p><br><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 4. 성능 지표 분석 </h2>\n",
    "<h3> 📊 초미세먼지(PM2.5) 모델의 성능 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** 훈련 세트 성능 평가 ***\n",
      "Confusion Matrix:\n",
      "[[TN, FP], [FN, TP]\n",
      "[[722, 98], [5, 50]] \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       양호(0)       0.99      0.88      0.93       820\n",
      "       나쁨(1)       0.34      0.91      0.49        55\n",
      "\n",
      "    accuracy                           0.88       875\n",
      "   macro avg       0.67      0.89      0.71       875\n",
      "weighted avg       0.95      0.88      0.91       875\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "*** 테스트 세트 성능 평가 ***\n",
      "Confusion Matrix:\n",
      "[[TN, FP], [FN, TP]\n",
      "[[154, 40], [5, 20]] \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       양호(0)       0.97      0.79      0.87       194\n",
      "       나쁨(1)       0.33      0.80      0.47        25\n",
      "\n",
      "    accuracy                           0.79       219\n",
      "   macro avg       0.65      0.80      0.67       219\n",
      "weighted avg       0.90      0.79      0.83       219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(pm25_pipeline, train_input_25, train_target_25, test_input_25, test_target_25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px\"> \n",
    "    훈련 세트에와 테스트 세트에서 정확도(Accuracy)가 각각 <b><mark>88점, 79점</mark></b>으로, 전반적으로 잘 학습하고 새로운 데이터에도 과적합이 심하지 않은 비교적 안정적인 성능을 발휘한다.<br><br>\n",
    "    초미세먼지 농도와 같이 보건 및 건강에 직결되는 데이터는 FN(False Negative)과 같은 치명적인 수치를 최소화해야 한다. 이를 위해 파이프라인에 샘플링 단계(SMOTEENN)를 추가하여 데이터 불균형을 해소했었다. 따라서 FN 데이터 개수는 훈련 세트에서 5개로 크게 감소시키며 <b>재현율(Recall)</b>을 <b><mark>91%</mark></b>(47/55)까지 끌어올렸다.<br><br>\n",
    "    그러나 FN 개수를 줄이는 동시에 FP(False Positive) 데이터 개수는 98개까지 폭증하면서 '나쁨(1)' 클래스의 <b>정밀도(Precision)</b>가 <b><mark>34점</mark></b>로 크게 하락하였다. <b>F1-점수</b>가 이로 인해 <b><mark>49점</mark></b>까지 낮아지면서 꽤 많은 거짓 정보를 발생시키는 모델이 되었다.<br><br>\n",
    "    이러한 훈련 과정에서의 특성은 모델의 실제 일반화 성능을 보여주는 테스트 세트에서도 일관되게 나타났다. 훈련 세트에서 준수했던 <b>재현율(Recall)</b>을 <b><mark>80%</mark></b>로 준수하게 유지했으며, 이는 실제 '나쁨(1)'인 날을 5일 중 4일을 예측해냈음을 의미한다. 하지만 훈련 세트에서 나타났던 <b>정밀도(Precision)</b>는 <b><mark>33점</mark></b>으로 낮았으며, <b>F1-점수</b>가 <b><mark>47점</mark></b>에 머물렀으나, 여전히 '양호'인 날을 '나쁨'으로 예측하는 FP 지표가 194개의 데이터 중 40개로 많았다.<br><br>\n",
    "    결론적으로 이 모델은 초미세먼지 '나쁨'을 놓치는 치명적 오류(FN)를 최소화하는 데는 성공했지만, FP 또한 폭증하여 신뢰하기에는 어려운 모델이 되었다. 그러나, 보건 및 건강에 직결되는 모델이기 때문에 실제 위험한 날을 더 많이 감지해낸다는 점에서 매우 <b>실용적</b>이며, 충분히 활용 가능성이 있는 모델이라고 할 수 있다.\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "<br><br>\n",
    "<h3>📊 미세먼지(PM10) 모델의 성능 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** 훈련 세트 성능 평가 ***\n",
      "Confusion Matrix:\n",
      "[[TN, FP], [FN, TP]\n",
      "[[755, 91], [0, 29]] \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       양호(0)       1.00      0.89      0.94       846\n",
      "       나쁨(1)       0.24      1.00      0.39        29\n",
      "\n",
      "    accuracy                           0.90       875\n",
      "   macro avg       0.62      0.95      0.67       875\n",
      "weighted avg       0.97      0.90      0.92       875\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "*** 테스트 세트 성능 평가 ***\n",
      "Confusion Matrix:\n",
      "[[TN, FP], [FN, TP]\n",
      "[[160, 53], [0, 6]] \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       양호(0)       1.00      0.75      0.86       213\n",
      "       나쁨(1)       0.10      1.00      0.18         6\n",
      "\n",
      "    accuracy                           0.76       219\n",
      "   macro avg       0.55      0.88      0.52       219\n",
      "weighted avg       0.98      0.76      0.84       219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(pm10_pipeline, train_input_10, train_target_10, test_input_10, test_target_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px\">\n",
    "훈련 세트와 테스트 세트의 정확도(Accuracy)가 각각 <b><mark>90%</mark></b>와 <b><mark>76%</mark></b>로, 훈련 성과에 비해 새로운 데이터에 대한 일반화 성능이 다소 떨어지는 과적합 경향을 보인다.<br><br>\n",
    "FN(False Negative)을 최소화하기 위한 전략으로, 훈련 세트에서 <b>재현율(Recall)</b>을 <b><mark>100%</mark></b>까지 달성하며 실제 '나쁨(1)'인 날을 전혀 놓치지 않았다. 이러한 특성은 테스트 세트에서도 유지되어, 실제 '나쁨(1)'인 날 6개를 모두 예측하며 <b>재현율(Recall) 100%</b>라는 완벽한 결과를 보였다.<br><br> 중요한 재현율을 완벽하게 클래스 수의 역수 가중치로 증가시킬 수 있기 때문에, 초미세먼지 예측 모델과는 다르게 스모틴(SMOTEENN) 샘플링 단계를 사용하지 않았다.<br><br> 그러나 이처럼 높은 재현율을 만들었기 때문에, FP(False Positive) 데이터가 폭증했다. 훈련 세트에서 91개, 테스트 세트에서 53개의 FP가 발생하며, '나쁨(1)' 클래스의 <b>정밀도(Precision)</b>는 훈련 시 <b><mark>24점</mark></b>, 테스트 시 <b><mark>10점</mark></b>까지 급락하였다. 이로 인해 종합 성능 지표인 <b>F1-점수</b>는 테스트 세트에서 <b><mark>18점</mark></b>이라는 매우 낮은 수치를 기록했다.<br><br>\n",
    "결론적으로 이 모델은 '나쁨'인 날을 절대 놓치지 않겠다는 목표는 100% 달성했지만, 그 과정에서 너무 많은 거짓 정보(FP)를 발생시켜 사용자가 모델의 예측을 신뢰하기 어렵다. 따라서 실용성이 매우 떨어지므로 트리 기반 앙상블 모델인 XGBoost, LightGBM, RandomForest와 같은 모델로 로지스틱 회귀를 대체하거나 또 다른 알고리즘이 필요하다.\n",
    "</p><br><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 5. 결론 </h2>\n",
    "<p style=\"font-size:16px\">\n",
    "    - <strong>오차행렬(Confusion Matrix)</strong>과 <strong>분류 리포트(Classification Report)</strong>를 이용하여 평가 지표 분석 및 작성<br>\n",
    "    - <strong>SMOTEENN</strong> 샘플링과 <strong>클래스 개수 역수 가중치</strong>를 상황에 따라 적절하게 활용하여 데이터 불균형 문제 해소<br><br>\n",
    "    초미세먼지(PM2.5) 예측 모델은 과적합이 약간은 존재하기는 하나, 여전히 안정적이며, 재현율(Recall) 80%, 그리고 F1-점수(F1-score) 47점으로 <b>실제 활용가능성</b>을 보였다.\n",
    "    클래스 수 역수 가중치를 사용했을 때보다 SMOTEENN 샘플링 단계를 추가했을 때, 재현율을 5% 더 확보할 수 있었고, 정밀도(Precision) 또한 오히려 상승했다.<br><br>\n",
    "    반면, 미세먼지(PM10) 예측 모델은 훈련 세트의 정확도(Accuracy)는 90%이지만 테스트 세트의 정확도(Accuracy)가 76%로 과대적합 경향을 보였다. 재현율(Recall)은 100%를 기록했으나, 정밀도(Precision) 10점, F1-점수(F1-score) 18점으로 신뢰할 수 없음을 보였다.<br><br>\n",
    "    초미세먼지 예측 모델과 미세먼지 예측 모델 둘 다 트리 기반 앙상블 모델을 이용해서 이진 분류를 한다면 더욱 개선될 것이라고 생각한다.\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
